// ğŸš€ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®š
const { Pool } = require('pg');
const Redis = require('redis');

// PostgreSQL æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®šï¼ˆçˆ†é€ŸåŒ–ä»•æ§˜ï¼‰
const dbPool = new Pool({
  connectionString: process.env.DATABASE_URL,
  // ğŸ”¥ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®š
  max: 50,           // æœ€å¤§æ¥ç¶šæ•°ï¼š50ï¼ˆé«˜è² è·å¯¾å¿œï¼‰
  min: 10,           // æœ€å°æ¥ç¶šæ•°ï¼š10ï¼ˆå¸¸æ™‚å¾…æ©Ÿï¼‰
  idleTimeoutMillis: 30000,  // ã‚¢ã‚¤ãƒ‰ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼š30ç§’
  connectionTimeoutMillis: 5000,  // æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼š5ç§’
  acquireTimeoutMillis: 60000,    // å–å¾—ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼š60ç§’
  
  // ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–è¨­å®š
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false,
  application_name: 'ultra_sync_ecommerce',
  
  // ğŸ”¥ æ¥ç¶šå“è³ªå‘ä¸Šè¨­å®š
  keepAlive: true,
  keepAliveInitialDelayMillis: 10000,
});

// Redis ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®šï¼ˆç•°æ¬¡å…ƒé€Ÿåº¦ï¼‰
const redisClient = Redis.createClient({
  url: process.env.REDIS_URL || 'redis://localhost:6379',
  retry_strategy: (options) => {
    if (options.error && options.error.code === 'ECONNREFUSED') {
      return new Error('Redis server refused connection');
    }
    if (options.total_retry_time > 1000 * 60 * 60) {
      return new Error('Redis retry time exhausted');
    }
    if (options.attempt > 10) {
      return undefined;
    }
    return Math.min(options.attempt * 100, 3000);
  }
});

// ğŸš€ ã‚¦ãƒ«ãƒˆãƒ©ã‚·ãƒ³ã‚¯ ã‚¯ã‚¨ãƒªå®Ÿè¡Œé–¢æ•°
async function executeQuery(sql, params = []) {
  const client = await dbPool.connect();
  try {
    const start = Date.now();
    const result = await client.query(sql, params);
    const duration = Date.now() - start;
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°ï¼ˆ100msä»¥ä¸Šã®å ´åˆè­¦å‘Šï¼‰
    if (duration > 100) {
      console.warn(`âš¡ Slow Query Detected: ${duration}ms - ${sql.substring(0, 100)}...`);
    }
    
    return result;
  } finally {
    client.release();
  }
}

// ğŸ”¥ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãã‚¯ã‚¨ãƒªå®Ÿè¡Œ
async function cachedQuery(cacheKey, sql, params = [], ttl = 300) {
  try {
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—è©¦è¡Œ
    const cached = await redisClient.get(cacheKey);
    if (cached) {
      
      return JSON.parse(cached);
    }
    
    // DBã‹ã‚‰å–å¾—
    const result = await executeQuery(sql, params);
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
    await redisClient.setex(cacheKey, ttl, JSON.stringify(result.rows));
    
    
    return result.rows;
  } catch (error) {
    console.error('Cache query error:', error);
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ©ãƒ¼æ™‚ã¯DBã‹ã‚‰ç›´æ¥å–å¾—
    const result = await executeQuery(sql, params);
    return result.rows;
  }
}

// ğŸš€ ãƒãƒƒãƒå‡¦ç†æœ€é©åŒ–é–¢æ•°
async function batchInsert(table, records, batchSize = 1000) {
  const batches = [];
  for (let i = 0; i < records.length; i += batchSize) {
    batches.push(records.slice(i, i + batchSize));
  }
  
  
  
  for (const batch of batches) {
    const values = batch.map((_, index) => 
      `(${batch[0].map((_, colIndex) => `$${index * batch[0].length + colIndex + 1}`).join(', ')})`
    ).join(', ');
    
    const flatValues = batch.flat();
    const sql = `INSERT INTO ${table} VALUES ${values}`;
    
    await executeQuery(sql, flatValues);
  }
}

module.exports = {
  dbPool,
  redisClient,
  executeQuery,
  cachedQuery,
  batchInsert
};